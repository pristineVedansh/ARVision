{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference between traditional and current feature detection?\n",
    "<img src=\"files/2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is deep in Deep Learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As Jeff Dean quoted \"deep\" refers to the large number of layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Fundamentals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pixels - The building blocks of image.\n",
    "A pixel is considered as \"color\" or \"intensity\" of the light at the particular point. Image can be conceptualize as multidimensional matrix.\n",
    "Most pixels are represented in two ways:\n",
    "1. Grayscale/ Single channel -  Each pixel is a scalar value between 0 and 255, where \"0\" corresponds to \"black\" and \"255\" corresponds to \"white\". And values between 0 and 255 correspond to various shades of grey.\n",
    "2. Color/ Multiple channel - Each pixel is demonstrated in the **RGB** color space and no longer holds a single value like grayscale. Each pixel is represented by **3 values**, each for red, green, and blue. Color in RGB channel is defined by **the amount of color**. Each red, blue, and green have values in range **[0, 255]**, where 0 indicates no representation and 255 full representation. The RGB color space is an example of an additive color space: the more of each color is added, the brighter the pixel becomes and closer to white."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We count from 0 rather than 1.<img src=\"files/3.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(411, 244, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "image = cv2.imread(\"files/2.png\")\n",
    "print(image.shape)\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notation is **(height, width, depth)**. This image has a width of 244 pixels (the number of columns), a height of 411 pixels (the\n",
    "number of rows), and a depth of 3 (the number of channels). To access an individual pixel value\n",
    "from our **image** we use simple NumPy array indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(r, g, b) = image[20, 100]) # accesses pixel at x=100, y=20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenCV stores **RGB** channel pixels value in reverse order as **BGR**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Classification Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Gather datset\n",
    "We need images with labels associated with them. The number of images in each category should be uniform. If we increase the number of images in any categories then classifier will became naturally baised to overfitting into these heavily represented categories. Avoid *class imbalance* completely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Split your dataset\n",
    "Splitting dataset into training set and test set. Itâ€™s extremely important that the training set and testing set are independent of each other and do not overlap! We split dataset in the following ratio. <img src=\"files/4.png\">\n",
    "In practice, we need to test a bunch of these hyperparameters and identify the set of parameters that works the best. **We normally allocate roughly 10-20% of the training data for validation.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Training a network\n",
    "This is what deep learning is about."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 - Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
