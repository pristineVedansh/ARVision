{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important points\n",
    "- Most simple machine learning algorithm. It doesn't actually learn anything.\n",
    "- This algorithm rely on distance between the feature vectors(in case of image it's the raw RGB pixel intensities).\n",
    "- The kNN algorithm classifies unknown data points by finding the *most common class* among the *k closest examples*.\n",
    "- The primary _assumption_ is that image with same visual contect should lie closer.\n",
    "- To find the similarity, we need to slect a distance metric or similarity function. \n",
    "    - L2 *or* Eucledian distance\n",
    "    - L1 *or* Manhattan distance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-NN Hyperparameters\n",
    "There are two hyper parameters associated with k-NN.\n",
    "- The value of k.\n",
    "- Chosing between L1 and L2 distance. Questioning which one is the best?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing k-NN using Animals dataset\n",
    "- Step 1 - **Gather our datset** - The Animals dataset consists of 3000 images with 1000 images per dog, cat, and pandas class. Represnted in RGB colorspace. Preprocess image by resizing it to 32 $\\times$ 32 pixels. Each image in  dataset is represented by 32 $\\times$ 32 $\\times$ 3 = 3072 integers.\n",
    "- Step 2 - **Split the dataset** - Two split for now: training and testing. Sometimes we split training into validation set also.\n",
    "- Step 3 - **Train the classifier** - Our k-NN classifier will be traine d on the law pixel intensities of the images in the training set.\n",
    "- Step 4 - **Evaluation on the test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n",
      "[INFO] processed 500/2000\n",
      "[INFO] processed 1000/2000\n",
      "[INFO] processed 1500/2000\n",
      "[INFO] processed 2000/2000\n",
      "[INFO features matrix: 6.0MB\n",
      "[INFO] evaluating k-NN classifier...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ed6f9ce900af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"[INFO] evaluating k-NN classifier...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"neighbors\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"jobs\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\sklearn\\neighbors\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    914\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 916\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    917\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\sklearn\\neighbors\\base.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    237\u001b[0m             \u001b[1;31m# and KDTree is generally faster when available\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m             if ((self.n_neighbors is None or\n\u001b[1;32m--> 239\u001b[1;33m                  self.n_neighbors < self._fit_X.shape[0] // 2) and\n\u001b[0m\u001b[0;32m    240\u001b[0m                     self.metric != 'precomputed'):\n\u001b[0;32m    241\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meffective_metric_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mVALID_METRICS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'kd_tree'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from preprocessing.simplepreprocessor import SimplePreprocessor\n",
    "from datasets.simpledatasetloader import SimpleDatasetLoader\n",
    "from imutils import paths\n",
    "import argparse\n",
    "\n",
    "# construct argument parse and parse the arguments\n",
    "#ap = argparse.ArgumentParser()\n",
    "#ap.add_argument(\"-d\", \"--dataset\", required=True, help=\"path to input datset\")\n",
    "#ap.add_argument(\"-k\", \"--neighbors\", type=int, default=1, help=\"# of nearest neighbors for classification\")\n",
    "#ap.add_argument(\"-j\", \"--jobs\", type=int, default=-1, help=\"# of jobs fpr k-NN distance (-1 uses all available cores)\")\n",
    "#args = vars(ap.parse_args())\n",
    "\n",
    "# arguments\n",
    "args = {\"dataset\" : \"I:\\ARVision\\datasets\\dataset\", \"neighbors\" : \"3\", \"jobs\" : \"-1\"}\n",
    "\n",
    "print(\"[INFO] loading images...\")\n",
    "imagePaths = list(paths.list_images(args[\"dataset\"]))\n",
    "\n",
    "# initialize the image preprocessor, load the datset from disk, and reshape the data matrix\n",
    "sp = SimplePreprocessor(32, 32)\n",
    "sdl = SimpleDatasetLoader(preprocessors=[sp])\n",
    "(data, labels) = sdl.load(imagePaths, verbose=500)\n",
    "data = data.reshape((data.shape[0], 3072))\n",
    "\n",
    "# show some information about images\n",
    "print(\"[INFO features matrix: {:.1f}MB\".format(data.nbytes / (1024*1000.0)))\n",
    "\n",
    "# encoding the labels as integers\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "\n",
    "# partition the data into training and testing splits\n",
    "(trainX, testX, trainY, testY)  = train_test_split(data, labels, test_size=0.25, random_state=42)\n",
    "\n",
    "# train and evaluate a k-NN classifier on raw pixel intensities\n",
    "print(\"[INFO] evaluating k-NN classifier...\")\n",
    "model = KNeighborsClassifier(n_neighbors=args[\"neighbors\"], n_jobs=args[\"jobs\"])\n",
    "model.fit(trainX, trainY)\n",
    "print(classification_report(testY, model.predict(testX), target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pros and cons of k-NN\n",
    "- Extremely simple to implement and understand.\n",
    "- We simply store our data points for computing distances to them and obtaining our final classification.\n",
    "- However, this is not effecient because classifying every **test data point** requires comparison to every **training data point**, which scales to $O(n)$, thereby making working with large data points prohibitive.\n",
    "- This time cost can be combat by **Approximate Nearest Neighbor** algorithms like kd-trees, FLANN etc. but using these requires us to trade our time complexity for accuracy fro nearest neighbor.\n",
    "- k-NN algorithms are more suited for low dimensional feature space, which images are not. $[70]$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-NN in aspects of data of large size in GB/TB\n",
    "- The most important issue is that k-NN stores **replica of whole training data** in the model. \n",
    "- Why keeping replica is an issue? Imagine size of data to be in GB/TB and think!\n",
    "- The more desirable approach would be defining a machine learning model that can **learn patterns from training data**, but have benefit of being **defined by small number of parameters** regardless of size of training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
